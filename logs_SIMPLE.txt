2025-05-10 12:42:56,940 - INFO - Starting improved evaluation with test file: data/nsl_kdd_dataset/NSL-KDD-Test.csv
2025-05-10 12:42:56,940 - INFO - Using model directory: saved_models
2025-05-10 12:42:56,940 - INFO - Results will be saved to: evaluation_results/complete_results.json
2025-05-10 12:42:56,940 - INFO - Starting threshold detector evaluation...
2025-05-10 12:42:56,940 - INFO - Using threshold detector model: saved_models/threshold_detector_1746776936
2025-05-10 12:42:57.643159: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:42:57.803618: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:42:58.423315: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:42:58.423404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:42:58.423415: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:42:59,037 - __main__ - INFO - Evaluating threshold detector: saved_models/threshold_detector_1746776936
2025-05-10 12:42:59,038 - __main__ - INFO - Loaded normalization parameters
2025-05-10 12:42:59,181 - __main__ - INFO - Loaded processed test file: data/nsl_kdd_dataset/NSL-KDD-Test.csv
2025-05-10 12:42:59,181 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:42:59,541 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:42:59,618 - data.loader - INFO -   test  shape: (22544, 45)
2025-05-10 12:42:59,893 - __main__ - INFO - Using 123 features
2025-05-10 12:42:59,934 - __main__ - INFO - Saved metrics to evaluation_results/threshold_detector/threshold_detector_metrics.json
2025-05-10 12:42:59,939 - __main__ - INFO - Successfully evaluated threshold
2025-05-10 12:42:59,950 - __main__ - INFO - Threshold detector evaluation completed successfully
2025-05-10 12:43:00,303 - INFO - Threshold detector evaluation completed successfully
2025-05-10 12:43:00,303 - INFO - Starting neural network models evaluation...
2025-05-10 12:43:00,304 - INFO - Step 1: Collecting raw predictions for neural models...
2025-05-10 12:43:00.442721: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:43:00.596037: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:43:01.225239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:43:01.225318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:43:01.225327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:43:02,148 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:43:02,519 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:43:02,595 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,42) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:43:02,890 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + alignâ€¦
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
2025-05-10 12:43:03,172 - evaluator - INFO - Hard set: 22545 samples Ã— 123 features
2025-05-10 12:43:03,187 - __main__ - INFO - Collecting predictions for dnn (dnn_1746776936)
2025-05-10 12:43:03.323285: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:43:03.965393: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-05-10 12:43:03.965416: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-05-10 12:43:03.965556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5180 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:04,072 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:04,709 - evaluator - INFO - Applied normalization from saved_models/dnn_1746776936
 1/89 [..............................] - ETA: 58s27/89 [========>.....................] - ETA: 0s 53/89 [================>.............] - ETA: 0s79/89 [=========================>....] - ETA: 0s89/89 [==============================] - 1s 2ms/step
2025-05-10 12:43:05,654 - __main__ - INFO - Collecting predictions for gru (gru_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:05,758 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:08,325 - evaluator - INFO - Applied normalization from saved_models/gru_1746776936
2025-05-10 12:43:09.253782: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
 1/89 [..............................] - ETA: 1:3619/89 [=====>........................] - ETA: 0s  37/89 [===========>..................] - ETA: 0s55/89 [=================>............] - ETA: 0s75/89 [========================>.....] - ETA: 0s89/89 [==============================] - 1s 3ms/step
2025-05-10 12:43:09,759 - __main__ - INFO - Collecting predictions for linear (linear_model_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:09,776 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:09,901 - evaluator - INFO - Applied normalization from saved_models/linear_model_1746776936
 1/89 [..............................] - ETA: 3s43/89 [=============>................] - ETA: 0s80/89 [=========================>....] - ETA: 0s89/89 [==============================] - 0s 1ms/step
2025-05-10 12:43:10,124 - __main__ - INFO - Collecting predictions for lstm (lstm_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:10,352 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:18,753 - evaluator - INFO - Applied normalization from saved_models/lstm_1746776936
 1/89 [..............................] - ETA: 1:4515/89 [====>.........................] - ETA: 0s  28/89 [========>.....................] - ETA: 0s41/89 [============>.................] - ETA: 0s54/89 [=================>............] - ETA: 0s65/89 [====================>.........] - ETA: 0s76/89 [========================>.....] - ETA: 0s88/89 [============================>.] - ETA: 0s89/89 [==============================] - 2s 4ms/step
2025-05-10 12:43:20,405 - __main__ - INFO - Collecting predictions for shallow (shallow_dnn_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:20,456 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:20,851 - evaluator - INFO - Applied normalization from saved_models/shallow_dnn_1746776936
 1/89 [..............................] - ETA: 6s38/89 [===========>..................] - ETA: 0s76/89 [========================>.....] - ETA: 0s89/89 [==============================] - 0s 1ms/step
2025-05-10 12:43:21,108 - __main__ - INFO - Collecting predictions for threshold (threshold_detector_1746776936)
2025-05-10 12:43:21,108 - __main__ - ERROR - Error collecting predictions for threshold_detector_1746776936: SavedModel file does not exist at: saved_models/threshold_detector_1746776936/{saved_model.pbtxt|saved_model.pb}
2025-05-10 12:43:21,108 - __main__ - INFO - Collecting predictions for transformer (transformer_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:21,185 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:21,907 - evaluator - INFO - Applied normalization from saved_models/transformer_1746776936
 1/89 [..............................] - ETA: 9s16/89 [====>.........................] - ETA: 0s31/89 [=========>....................] - ETA: 0s45/89 [==============>...............] - ETA: 0s59/89 [==================>...........] - ETA: 0s73/89 [=======================>......] - ETA: 0s85/89 [===========================>..] - ETA: 0s89/89 [==============================] - 0s 4ms/step
2025-05-10 12:43:22,444 - __main__ - INFO - All predictions saved to evaluation_results/predictions
2025-05-10 12:43:23,938 - INFO - Step 2: Measuring performance for neural models...
2025-05-10 12:43:24.081856: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:43:24.230619: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:43:24.865082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:43:24.865166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:43:24.865178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:43:25,722 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:43:26,076 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:43:26,150 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,42) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:43:26,429 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + alignâ€¦
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
2025-05-10 12:43:26,701 - evaluator - INFO - Hard set: 22545 samples Ã— 123 features
2025-05-10 12:43:26,715 - __main__ - INFO - Feature extraction time: 992.94 ms
2025-05-10 12:43:26,715 - __main__ - INFO - Measuring performance for dnn (dnn_1746776936)
2025-05-10 12:43:26.850283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:43:27.479931: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-05-10 12:43:27.479954: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-05-10 12:43:27.480091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5190 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:27,580 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 606ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
2025-05-10 12:43:31,764 - __main__ - INFO - Measuring performance for gru (gru_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:31,878 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:35.190997: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 1s/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
2025-05-10 12:43:38,453 - __main__ - INFO - Measuring performance for linear (linear_model_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:38,473 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
2025-05-10 12:43:41,667 - __main__ - INFO - Measuring performance for lstm (lstm_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:41,891 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 1s/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 27ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
2025-05-10 12:43:54,070 - __main__ - INFO - Measuring performance for shallow (shallow_dnn_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:54,118 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 77ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
2025-05-10 12:43:57,650 - __main__ - INFO - Measuring performance for threshold (threshold_detector_1746776936)
2025-05-10 12:43:57,650 - __main__ - ERROR - Error measuring performance for threshold_detector_1746776936: SavedModel file does not exist at: saved_models/threshold_detector_1746776936/{saved_model.pbtxt|saved_model.pb}
2025-05-10 12:43:57,650 - __main__ - INFO - Measuring performance for transformer (transformer_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:43:57,753 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 101ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 27ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
2025-05-10 12:44:02,559 - __main__ - INFO - Performance measurements saved to evaluation_results/timing and evaluation_results/memory
2025-05-10 12:44:03,386 - INFO - Step 3: Analyzing attack types for neural models...
2025-05-10 12:44:03.696029: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:44:03.838863: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:44:04.392496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:44:04.392611: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:44:04.392624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
analyze_attack_types.py:32: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,42) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_df = pd.read_csv(test_file, header=None)
2025-05-10 12:44:05,444 - __main__ - WARNING - Length mismatch: attack_labels (22544) != y_true (22545)
2025-05-10 12:44:05,448 - __main__ - WARNING - Length mismatch: y_probs (22545) != y_true (22544)
2025-05-10 12:44:05,541 - __main__ - WARNING - Length mismatch: y_probs (22545) != y_true (22544)
2025-05-10 12:44:05,627 - __main__ - WARNING - Length mismatch: y_probs (22545) != y_true (22544)
2025-05-10 12:44:05,715 - __main__ - WARNING - Length mismatch: y_probs (22545) != y_true (22544)
2025-05-10 12:44:05,797 - __main__ - WARNING - Length mismatch: y_probs (22545) != y_true (22544)
2025-05-10 12:44:05,878 - __main__ - WARNING - Length mismatch: y_probs (22545) != y_true (22544)
2025-05-10 12:44:06,044 - __main__ - INFO - Attack type analysis saved to evaluation_results/attack_types
2025-05-10 12:44:06,361 - INFO - Step 4: Analyzing scalability for neural models...
2025-05-10 12:44:06.519620: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:44:06.666609: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:44:07.276739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:44:07.276814: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:44:07.276823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:44:08,340 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:44:08,702 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:44:08,786 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,42) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:44:09,079 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + alignâ€¦
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
2025-05-10 12:44:09,350 - evaluator - INFO - Hard set: 22545 samples Ã— 123 features
2025-05-10 12:44:09,364 - __main__ - INFO - Scalability analysis saved to evaluation_results/scalability
2025-05-10 12:44:09,720 - INFO - Step 5: Testing statistical significance for neural models...
2025-05-10 12:44:09.874492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:44:10.030190: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:44:10.680705: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:44:10.680779: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:44:10.680799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:44:11,751 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:44:12,104 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:44:12,179 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,42) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:44:12,460 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + alignâ€¦
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
2025-05-10 12:44:12,733 - evaluator - INFO - Hard set: 22545 samples Ã— 123 features
2025-05-10 12:44:12,747 - __main__ - INFO - Testing shallow (shallow_dnn_1746776936)
2025-05-10 12:44:12,747 - __main__ - INFO - Testing lstm (lstm_1746776936)
2025-05-10 12:44:12,747 - __main__ - INFO - Testing threshold (threshold_detector_1746776936)
2025-05-10 12:44:12,747 - __main__ - INFO - Testing dnn (dnn_1746776936)
2025-05-10 12:44:12,747 - __main__ - INFO - Testing transformer (transformer_1746776936)
2025-05-10 12:44:12,747 - __main__ - INFO - Testing linear (linear_model_1746776936)
2025-05-10 12:44:12,747 - __main__ - INFO - Testing gru (gru_1746776936)
2025-05-10 12:44:12,747 - __main__ - INFO - Statistical significance test results saved to evaluation_results/significance
2025-05-10 12:44:13,085 - INFO - Step 6: Analyzing model interpretability for neural models...
2025-05-10 12:44:13.217668: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:44:13.365480: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:44:13.967915: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:44:13.967995: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:44:13.968005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:44:15,166 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:44:15,519 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:44:15,593 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,42) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:44:15,878 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + alignâ€¦
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = hard_enc[col]
2025-05-10 12:44:16,150 - evaluator - INFO - Hard set: 22545 samples Ã— 123 features
2025-05-10 12:44:16,164 - __main__ - INFO - Analyzing interpretability for dnn (dnn_1746776936)
2025-05-10 12:44:16.310655: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:44:16.982106: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-05-10 12:44:16.982141: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-05-10 12:44:16.982278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5190 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:17,091 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:17,659 - evaluator - INFO - Applied normalization from saved_models/dnn_1746776936
 1/16 [>.............................] - ETA: 9s16/16 [==============================] - 1s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
2025-05-10 12:44:21,989 - __main__ - INFO - Analyzing interpretability for gru (gru_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:22,108 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:24,700 - evaluator - INFO - Applied normalization from saved_models/gru_1746776936
2025-05-10 12:44:25.611141: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
 1/16 [>.............................] - ETA: 15s16/16 [==============================] - 1s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
2025-05-10 12:44:30,173 - __main__ - INFO - Analyzing interpretability for linear (linear_model_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:30,193 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:30,325 - evaluator - INFO - Applied normalization from saved_models/linear_model_1746776936
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 991us/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 976us/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
2025-05-10 12:44:33,707 - __main__ - INFO - Analyzing interpretability for lstm (lstm_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:33,929 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:41,759 - evaluator - INFO - Applied normalization from saved_models/lstm_1746776936
 1/16 [>.............................] - ETA: 16s15/16 [===========================>..] - ETA: 0s 16/16 [==============================] - 1s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s11/16 [===================>..........] - ETA: 0s16/16 [==============================] - 0s 5ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 5ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s12/16 [=====================>........] - ETA: 0s16/16 [==============================] - 0s 5ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
2025-05-10 12:44:48,302 - __main__ - INFO - Analyzing interpretability for shallow (shallow_dnn_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:48,359 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:48,812 - evaluator - INFO - Applied normalization from saved_models/shallow_dnn_1746776936
 1/16 [>.............................] - ETA: 1s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
2025-05-10 12:44:52,493 - __main__ - INFO - Analyzing interpretability for threshold (threshold_detector_1746776936)
2025-05-10 12:44:52,493 - __main__ - ERROR - Error analyzing interpretability for threshold_detector_1746776936: SavedModel file does not exist at: saved_models/threshold_detector_1746776936/{saved_model.pbtxt|saved_model.pb}
2025-05-10 12:44:52,493 - __main__ - INFO - Analyzing interpretability for transformer (transformer_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:52,585 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:44:54,193 - evaluator - INFO - Applied normalization from saved_models/transformer_1746776936
 1/16 [>.............................] - ETA: 1s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
2025-05-10 12:44:59,366 - __main__ - INFO - Model interpretability analysis saved to evaluation_results/interpretability
2025-05-10 12:45:00,258 - INFO - Neural network models evaluation completed
2025-05-10 12:45:00,267 - INFO - Created consistent ground truth file at evaluation_results/predictions/y_true.npy
2025-05-10 12:45:00,267 - INFO - Created consistent ground truth file at evaluation_results/threshold_detector/predictions/y_true.npy
2025-05-10 12:45:00,268 - INFO - Generating combined evaluation results...
2025-05-10 12:45:00,652 - INFO - Calculated metrics for threshold
2025-05-10 12:45:00,675 - INFO - Calculated metrics for threshold
2025-05-10 12:45:00,677 - INFO - Consolidated results saved to evaluation_results/complete_results.json
2025-05-10 12:45:00,677 - INFO - Generating visualizations...
2025-05-10 12:45:00,677 - INFO - Generating visualizations...
2025-05-10 12:45:00,678 - INFO - Created consistent ground truth file at evaluation_results/predictions/y_true.npy
2025-05-10 12:45:00,678 - INFO - Created consistent ground truth file at evaluation_results/threshold_detector/predictions/y_true.npy
2025-05-10 12:45:01,674 - __main__ - WARNING - No training history files found
2025-05-10 12:45:01,677 - __main__ - WARNING - Prediction length mismatch for shallow: 22545 vs 22544
2025-05-10 12:45:01,677 - __main__ - WARNING - Prediction length mismatch for gru: 22545 vs 22544
2025-05-10 12:45:01,678 - __main__ - WARNING - Prediction length mismatch for dnn: 22545 vs 22544
2025-05-10 12:45:01,678 - __main__ - WARNING - Prediction length mismatch for lstm: 22545 vs 22544
2025-05-10 12:45:01,678 - __main__ - WARNING - Prediction length mismatch for transformer: 22545 vs 22544
2025-05-10 12:45:01,679 - __main__ - WARNING - Prediction length mismatch for linear: 22545 vs 22544
2025-05-10 12:45:02,878 - __main__ - INFO - ROC and PR curves saved
2025-05-10 12:45:02,879 - __main__ - WARNING - Prediction length mismatch for shallow: 22545 vs 22544
2025-05-10 12:45:02,880 - __main__ - WARNING - Prediction length mismatch for gru: 22545 vs 22544
2025-05-10 12:45:02,880 - __main__ - WARNING - Prediction length mismatch for dnn: 22545 vs 22544
2025-05-10 12:45:02,880 - __main__ - WARNING - Prediction length mismatch for lstm: 22545 vs 22544
2025-05-10 12:45:02,880 - __main__ - WARNING - Prediction length mismatch for transformer: 22545 vs 22544
2025-05-10 12:45:02,881 - __main__ - WARNING - Prediction length mismatch for linear: 22545 vs 22544
fixed_generate_visualizations.py:360: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
2025-05-10 12:45:09,233 - __main__ - INFO - Threshold analysis plot saved
2025-05-10 12:45:10,119 - __main__ - INFO - Detection time breakdown saved
2025-05-10 12:45:10,120 - __main__ - WARNING - No common models found across all datasets
2025-05-10 12:45:11,385 - __main__ - INFO - Attack-specific performance visualizations saved
2025-05-10 12:45:11,385 - __main__ - WARNING - No scalability data available
2025-05-10 12:45:11,385 - __main__ - WARNING - No significance test data available
2025-05-10 12:45:15,517 - __main__ - INFO - Transformer attention visualization saved
2025-05-10 12:45:15,517 - __main__ - INFO - Model interpretability visualizations saved
2025-05-10 12:45:15,517 - __main__ - INFO - All visualizations saved to plots/model_profiles
2025-05-10 12:45:15,824 - INFO - Visualizations generation completed
2025-05-10 12:45:15,825 - INFO - Evaluation pipeline completed!
2025-05-10 12:45:15,825 - INFO - Log file saved to: evaluation_log_20250510_124256.txt
