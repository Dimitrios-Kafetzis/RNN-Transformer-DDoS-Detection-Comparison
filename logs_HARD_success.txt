2025-05-10 12:33:56,646 - INFO - Starting improved evaluation with test file: data/nsl_kdd_dataset/NSL-KDD-Hard.csv
2025-05-10 12:33:56,646 - INFO - Using model directory: saved_models
2025-05-10 12:33:56,646 - INFO - Results will be saved to: evaluation_results/complete_results.json
2025-05-10 12:33:56,647 - INFO - Starting threshold detector evaluation...
2025-05-10 12:33:56,647 - INFO - Using threshold detector model: saved_models/threshold_detector_1746776936
2025-05-10 12:33:57.320982: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:33:57.463312: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:33:58.055009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:33:58.055105: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:33:58.055115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:33:58,655 - __main__ - INFO - Evaluating threshold detector: saved_models/threshold_detector_1746776936
2025-05-10 12:33:58,656 - __main__ - INFO - Loaded normalization parameters
2025-05-10 12:33:58,840 - __main__ - INFO - Loaded processed test file: data/nsl_kdd_dataset/NSL-KDD-Hard.csv
2025-05-10 12:33:58,840 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:33:59,188 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:33:59,263 - data.loader - INFO -   test  shape: (22544, 45)
2025-05-10 12:33:59,479 - __main__ - INFO - Using 123 features
2025-05-10 12:33:59,501 - __main__ - INFO - Saved metrics to evaluation_results/threshold_detector/threshold_detector_metrics.json
2025-05-10 12:33:59,505 - __main__ - INFO - Successfully evaluated threshold
2025-05-10 12:33:59,518 - __main__ - INFO - Threshold detector evaluation completed successfully
2025-05-10 12:33:59,839 - INFO - Threshold detector evaluation completed successfully
2025-05-10 12:33:59,840 - INFO - Starting neural network models evaluation...
2025-05-10 12:33:59,840 - INFO - Step 1: Collecting raw predictions for neural models...
2025-05-10 12:33:59.982757: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:34:00.138789: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:34:00.810515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:34:00.810603: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:34:00.810614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:34:01,659 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:34:02,008 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:34:02,081 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:34:02,476 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + align…
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
2025-05-10 12:34:02,724 - evaluator - INFO - Hard set: 10001 samples × 123 features
2025-05-10 12:34:02,740 - __main__ - INFO - Collecting predictions for dnn (dnn_1746776936)
2025-05-10 12:34:02.881942: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:34:03.515334: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-05-10 12:34:03.515359: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-05-10 12:34:03.515480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5119 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:03,622 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:04,249 - evaluator - INFO - Applied normalization from saved_models/dnn_1746776936
 1/40 [..............................] - ETA: 22s32/40 [=======================>......] - ETA: 0s 40/40 [==============================] - 1s 2ms/step
2025-05-10 12:34:04,961 - __main__ - INFO - Collecting predictions for gru (gru_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:05,061 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:07,480 - evaluator - INFO - Applied normalization from saved_models/gru_1746776936
2025-05-10 12:34:08.368486: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
 1/40 [..............................] - ETA: 40s20/40 [==============>...............] - ETA: 0s 38/40 [===========================>..] - ETA: 0s40/40 [==============================] - 1s 3ms/step
2025-05-10 12:34:08,685 - __main__ - INFO - Collecting predictions for linear (linear_model_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:08,710 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:08,827 - evaluator - INFO - Applied normalization from saved_models/linear_model_1746776936
 1/40 [..............................] - ETA: 1s40/40 [==============================] - 0s 1ms/step
2025-05-10 12:34:08,936 - __main__ - INFO - Collecting predictions for lstm (lstm_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:09,148 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:16,983 - evaluator - INFO - Applied normalization from saved_models/lstm_1746776936
 1/40 [..............................] - ETA: 43s14/40 [=========>....................] - ETA: 0s 27/40 [===================>..........] - ETA: 0s39/40 [============================>.] - ETA: 0s40/40 [==============================] - 1s 4ms/step
2025-05-10 12:34:18,300 - __main__ - INFO - Collecting predictions for shallow (shallow_dnn_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:18,348 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:18,733 - evaluator - INFO - Applied normalization from saved_models/shallow_dnn_1746776936
 1/40 [..............................] - ETA: 2s34/40 [========================>.....] - ETA: 0s40/40 [==============================] - 0s 2ms/step
2025-05-10 12:34:18,901 - __main__ - INFO - Collecting predictions for threshold (threshold_detector_1746776936)
2025-05-10 12:34:18,902 - __main__ - ERROR - Error collecting predictions for threshold_detector_1746776936: SavedModel file does not exist at: saved_models/threshold_detector_1746776936/{saved_model.pbtxt|saved_model.pb}
2025-05-10 12:34:18,902 - __main__ - INFO - Collecting predictions for transformer (transformer_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:18,995 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:19,757 - evaluator - INFO - Applied normalization from saved_models/transformer_1746776936
 1/40 [..............................] - ETA: 4s15/40 [==========>...................] - ETA: 0s30/40 [=====================>........] - ETA: 0s40/40 [==============================] - 0s 4ms/step
2025-05-10 12:34:20,053 - __main__ - INFO - All predictions saved to evaluation_results/predictions
2025-05-10 12:34:21,489 - INFO - Step 2: Measuring performance for neural models...
2025-05-10 12:34:21.628126: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:34:21.768732: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:34:22.357890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:34:22.357969: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:34:22.357979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:34:23,204 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:34:23,556 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:34:23,632 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:34:24,024 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + align…
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
2025-05-10 12:34:24,271 - evaluator - INFO - Hard set: 10001 samples × 123 features
2025-05-10 12:34:24,287 - __main__ - INFO - Feature extraction time: 1082.38 ms
2025-05-10 12:34:24,287 - __main__ - INFO - Measuring performance for dnn (dnn_1746776936)
2025-05-10 12:34:24.425098: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:34:25.092739: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-05-10 12:34:25.092765: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-05-10 12:34:25.092889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5127 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:25,205 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 634ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
2025-05-10 12:34:29,639 - __main__ - INFO - Measuring performance for gru (gru_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:29,759 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:33.080902: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 1s/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 28ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
2025-05-10 12:34:36,388 - __main__ - INFO - Measuring performance for linear (linear_model_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:36,406 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
2025-05-10 12:34:39,735 - __main__ - INFO - Measuring performance for lstm (lstm_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:39,976 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 1s/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 28ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 28ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 65ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
2025-05-10 12:34:52,719 - __main__ - INFO - Measuring performance for shallow (shallow_dnn_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:52,768 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 70ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 27ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
2025-05-10 12:34:56,307 - __main__ - INFO - Measuring performance for threshold (threshold_detector_1746776936)
2025-05-10 12:34:56,307 - __main__ - ERROR - Error measuring performance for threshold_detector_1746776936: SavedModel file does not exist at: saved_models/threshold_detector_1746776936/{saved_model.pbtxt|saved_model.pb}
2025-05-10 12:34:56,307 - __main__ - INFO - Measuring performance for transformer (transformer_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:34:56,403 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 106ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
2025-05-10 12:35:01,222 - __main__ - INFO - Performance measurements saved to evaluation_results/timing and evaluation_results/memory
2025-05-10 12:35:02,070 - INFO - Step 3: Analyzing attack types for neural models...
2025-05-10 12:35:02.382597: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:35:02.539841: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:35:03.101711: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:35:03.101791: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:35:03.101811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
analyze_attack_types.py:32: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_df = pd.read_csv(test_file, header=None)
2025-05-10 12:35:04,251 - __main__ - WARNING - Length mismatch: attack_labels (10000) != y_true (10001)
2025-05-10 12:35:04,253 - __main__ - WARNING - Length mismatch: y_probs (10001) != y_true (10000)
2025-05-10 12:35:04,257 - __main__ - WARNING - Length mismatch: y_probs (10001) != y_true (10000)
2025-05-10 12:35:04,262 - __main__ - WARNING - Length mismatch: y_probs (10001) != y_true (10000)
2025-05-10 12:35:04,267 - __main__ - WARNING - Length mismatch: y_probs (10001) != y_true (10000)
2025-05-10 12:35:04,270 - __main__ - WARNING - Length mismatch: y_probs (10001) != y_true (10000)
2025-05-10 12:35:04,274 - __main__ - WARNING - Length mismatch: y_probs (10001) != y_true (10000)
2025-05-10 12:35:04,282 - __main__ - INFO - Attack type analysis saved to evaluation_results/attack_types
2025-05-10 12:35:04,615 - INFO - Step 4: Analyzing scalability for neural models...
2025-05-10 12:35:04.759063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:35:04.907590: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:35:05.559474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:35:05.559557: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:35:05.559569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:35:06,633 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:35:06,993 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:35:07,069 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:35:07,513 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + align…
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
2025-05-10 12:35:07,852 - evaluator - INFO - Hard set: 10001 samples × 123 features
2025-05-10 12:35:07,871 - __main__ - INFO - Scalability analysis saved to evaluation_results/scalability
2025-05-10 12:35:08,236 - INFO - Step 5: Testing statistical significance for neural models...
2025-05-10 12:35:08.376893: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:35:08.530510: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:35:09.169196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:35:09.169273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:35:09.169283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:35:10,256 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:35:10,621 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:35:10,699 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:35:11,099 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + align…
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
2025-05-10 12:35:11,427 - evaluator - INFO - Hard set: 10001 samples × 123 features
2025-05-10 12:35:11,443 - __main__ - INFO - Testing shallow (shallow_dnn_1746776936)
2025-05-10 12:35:11,443 - __main__ - INFO - Testing lstm (lstm_1746776936)
2025-05-10 12:35:11,443 - __main__ - INFO - Testing threshold (threshold_detector_1746776936)
2025-05-10 12:35:11,443 - __main__ - INFO - Testing dnn (dnn_1746776936)
2025-05-10 12:35:11,443 - __main__ - INFO - Testing transformer (transformer_1746776936)
2025-05-10 12:35:11,443 - __main__ - INFO - Testing linear (linear_model_1746776936)
2025-05-10 12:35:11,443 - __main__ - INFO - Testing gru (gru_1746776936)
2025-05-10 12:35:11,443 - __main__ - INFO - Statistical significance test results saved to evaluation_results/significance
2025-05-10 12:35:11,818 - INFO - Step 6: Analyzing model interpretability for neural models...
2025-05-10 12:35:11.955743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:35:12.108886: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-10 12:35:12.703716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:35:12.703805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-05-10 12:35:12.703814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-05-10 12:35:13,894 - data.loader - INFO - Loading NSL-KDD (both) from /home/dimitris/DoS_Attacks_Detector_v2/data/nsl_kdd_dataset
2025-05-10 12:35:14,243 - data.loader - INFO -   train shape: (125973, 45)
2025-05-10 12:35:14,317 - data.loader - INFO -   test  shape: (22544, 45)
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:40: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123) have mixed types. Specify dtype option on import or set low_memory=False.
  raw_hard = pd.read_csv(hard_csv, header=None, names=raw_train_df.columns)
2025-05-10 12:35:14,722 - evaluator - INFO - RAW Hard CSV detected; processing + one-hot + align…
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
/home/dimitris/DoS_Attacks_Detector_v2/generate_advanced_models_preds.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  hard_aligned[col] = 0
2025-05-10 12:35:14,967 - evaluator - INFO - Hard set: 10001 samples × 123 features
2025-05-10 12:35:14,982 - __main__ - INFO - Analyzing interpretability for dnn (dnn_1746776936)
2025-05-10 12:35:15.225288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-10 12:35:15.884399: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-05-10 12:35:15.884422: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-05-10 12:35:15.884559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5148 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:15,989 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:16,529 - evaluator - INFO - Applied normalization from saved_models/dnn_1746776936
 1/16 [>.............................] - ETA: 9s16/16 [==============================] - 1s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
2025-05-10 12:35:20,893 - __main__ - INFO - Analyzing interpretability for gru (gru_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:21,013 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:23,586 - evaluator - INFO - Applied normalization from saved_models/gru_1746776936
2025-05-10 12:35:24.476622: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
 1/16 [>.............................] - ETA: 15s16/16 [==============================] - 1s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
2025-05-10 12:35:29,178 - __main__ - INFO - Analyzing interpretability for linear (linear_model_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:29,202 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:29,329 - evaluator - INFO - Applied normalization from saved_models/linear_model_1746776936
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 983us/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 998us/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 999us/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 981us/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 973us/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 938us/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
2025-05-10 12:35:32,710 - __main__ - INFO - Analyzing interpretability for lstm (lstm_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:32,962 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:41,090 - evaluator - INFO - Applied normalization from saved_models/lstm_1746776936
 1/16 [>.............................] - ETA: 16s16/16 [==============================] - ETA: 0s 16/16 [==============================] - 1s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 5ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 5ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 5ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s 9/16 [===============>..............] - ETA: 0s16/16 [==============================] - 0s 6ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
2025-05-10 12:35:47,828 - __main__ - INFO - Analyzing interpretability for shallow (shallow_dnn_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:47,900 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:48,656 - evaluator - INFO - Applied normalization from saved_models/shallow_dnn_1746776936
 1/16 [>.............................] - ETA: 1s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 2ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 1ms/step
2025-05-10 12:35:52,510 - __main__ - INFO - Analyzing interpretability for threshold (threshold_detector_1746776936)
2025-05-10 12:35:52,510 - __main__ - ERROR - Error analyzing interpretability for threshold_detector_1746776936: SavedModel file does not exist at: saved_models/threshold_detector_1746776936/{saved_model.pbtxt|saved_model.pb}
2025-05-10 12:35:52,510 - __main__ - INFO - Analyzing interpretability for transformer (transformer_1746776936)
WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:52,612 - tensorflow - WARNING - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
2025-05-10 12:35:53,456 - evaluator - INFO - Applied normalization from saved_models/transformer_1746776936
 1/16 [>.............................] - ETA: 1s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s13/16 [=======================>......] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s14/16 [=========================>....] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s10/16 [=================>............] - ETA: 0s16/16 [==============================] - 0s 5ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s16/16 [==============================] - ETA: 0s16/16 [==============================] - 0s 3ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
 1/16 [>.............................] - ETA: 0s15/16 [===========================>..] - ETA: 0s16/16 [==============================] - 0s 4ms/step
2025-05-10 12:35:58,754 - __main__ - INFO - Model interpretability analysis saved to evaluation_results/interpretability
2025-05-10 12:36:00,407 - INFO - Neural network models evaluation completed
2025-05-10 12:36:00,416 - INFO - Created consistent ground truth file at evaluation_results/predictions/y_true.npy
2025-05-10 12:36:00,416 - INFO - Created consistent ground truth file at evaluation_results/threshold_detector/predictions/y_true.npy
2025-05-10 12:36:00,416 - INFO - Generating combined evaluation results...
2025-05-10 12:36:00,843 - INFO - Calculated metrics for threshold
2025-05-10 12:36:00,858 - INFO - Calculated metrics for threshold
2025-05-10 12:36:00,860 - INFO - Consolidated results saved to evaluation_results/complete_results.json
2025-05-10 12:36:00,860 - INFO - Generating visualizations...
2025-05-10 12:36:00,860 - INFO - Generating visualizations...
2025-05-10 12:36:00,862 - INFO - Created consistent ground truth file at evaluation_results/predictions/y_true.npy
2025-05-10 12:36:00,862 - INFO - Created consistent ground truth file at evaluation_results/threshold_detector/predictions/y_true.npy
2025-05-10 12:36:01,914 - __main__ - WARNING - No training history files found
2025-05-10 12:36:01,917 - __main__ - WARNING - Prediction length mismatch for shallow: 10001 vs 10000
2025-05-10 12:36:01,917 - __main__ - WARNING - Prediction length mismatch for gru: 10001 vs 10000
2025-05-10 12:36:01,918 - __main__ - WARNING - Prediction length mismatch for dnn: 10001 vs 10000
2025-05-10 12:36:01,918 - __main__ - WARNING - Prediction length mismatch for lstm: 10001 vs 10000
2025-05-10 12:36:01,918 - __main__ - WARNING - Prediction length mismatch for transformer: 10001 vs 10000
2025-05-10 12:36:01,919 - __main__ - WARNING - Prediction length mismatch for linear: 10001 vs 10000
2025-05-10 12:36:03,070 - __main__ - INFO - ROC and PR curves saved
2025-05-10 12:36:03,071 - __main__ - WARNING - Prediction length mismatch for shallow: 10001 vs 10000
2025-05-10 12:36:03,071 - __main__ - WARNING - Prediction length mismatch for gru: 10001 vs 10000
2025-05-10 12:36:03,071 - __main__ - WARNING - Prediction length mismatch for dnn: 10001 vs 10000
2025-05-10 12:36:03,072 - __main__ - WARNING - Prediction length mismatch for lstm: 10001 vs 10000
2025-05-10 12:36:03,072 - __main__ - WARNING - Prediction length mismatch for transformer: 10001 vs 10000
2025-05-10 12:36:03,072 - __main__ - WARNING - Prediction length mismatch for linear: 10001 vs 10000
fixed_generate_visualizations.py:360: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
2025-05-10 12:36:07,161 - __main__ - INFO - Threshold analysis plot saved
2025-05-10 12:36:08,177 - __main__ - INFO - Detection time breakdown saved
2025-05-10 12:36:08,178 - __main__ - WARNING - No common models found across all datasets
2025-05-10 12:36:08,178 - __main__ - WARNING - No valid attack types found
2025-05-10 12:36:08,178 - __main__ - WARNING - No scalability data available
2025-05-10 12:36:08,178 - __main__ - WARNING - No significance test data available
2025-05-10 12:36:08,178 - __main__ - WARNING - Importance matrix has identical values, adding small random perturbations
2025-05-10 12:36:12,451 - __main__ - INFO - Transformer attention visualization saved
2025-05-10 12:36:12,451 - __main__ - INFO - Model interpretability visualizations saved
2025-05-10 12:36:12,451 - __main__ - INFO - All visualizations saved to plots/model_profiles
2025-05-10 12:36:12,748 - INFO - Visualizations generation completed
2025-05-10 12:36:12,748 - INFO - Evaluation pipeline completed!
2025-05-10 12:36:12,748 - INFO - Log file saved to: evaluation_log_20250510_123356.txt
